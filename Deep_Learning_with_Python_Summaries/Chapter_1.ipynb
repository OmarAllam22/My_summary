{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e897fcc",
   "metadata": {},
   "source": [
    "# Chapter: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0e02a",
   "metadata": {},
   "source": [
    ">* `Artificial Intellegence` is trying automate intellectual tasks normally performed by humans. \n",
    "\n",
    ">* At early stages of AI, there are some applications didn't require learning, it is instead tried to hard code some rules to follow in order to automate tasks made by human. This is called `Symbolic AI` (ex: playing chess).\n",
    ">> This `Symbolic AI` differs from other data-drive AI paradaigm like machine learning. because this symbolic AI uses symbols and try to use logical and semantic rules on them. (it is similar to ordinary programming but doesn't use explicit set of code. It implements logical and semantic relations to do inference and can be used to make decision in expert systems in companies.)\n",
    "\n",
    ">* Recently another type of AI arises that based on learning. This is called `Machine learning`.\n",
    "\n",
    ">* Although `symbolic AI` proved suitable to solve well-defined, logical problems, such as playing chess, it turned out to be intractable and hard to figure out explicit rules for solving more complex, fuzzy problems, such as image classification, speech recognition, or natural language translation. Here the concept of learning comes into play to introduce `machine learning`\n",
    "\n",
    ">* To do machine learning, you need three things: ( 1. Input Data, 2. Expected output, 3. way to measure whether the algorithm is acting good.)\n",
    "\n",
    ">* Deep learning isn’t always the right tool for the job—sometimes there isn’t enough data for deep learning to be applicable, and sometimes the problem is better solved by a different algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3dfbc",
   "metadata": {},
   "source": [
    ">* There are some algorithms used before neural networks like:\n",
    ">>* `Probabilistic models` (ex: Naive Bayes, Logistic regression)\n",
    ">>* `Kernel Methods` (ex: Support Vector Machines, Adaptive Filtering, Principal Component Analysis, Kernel Perception, Spectral Clustering)\n",
    ">>> Note about SVM: SVMs proved hard to scale to large datasets and didn’t provide good results for perceptual problems such as image classification. Because an SVM is a shallow method, applying an SVM to perceptual problems requires first extracting useful representations manually (a step called feature engineering), which is difficult and brittle. For instance, if you want to use an SVM to classify handwritten digits, you can’t start from the raw pixels; you should first find by hand useful representations that make the problem more tractable, like the pixel histograms.\n",
    ">>* `Descision trees`, `Random Forests` and `Gradient Boosting`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ba9f6",
   "metadata": {},
   "source": [
    ">* **The primary reason** deep learning took off so quickly is that it offered better performance for many problems. But that’s not the only reason. Deep learning also makes problem-solving much easier, because it **completely automates** what used to be the most crucial step in a machine learning workflow: **feature engineering**.\n",
    "\n",
    ">* **Could shallow methods be applied repeatedly to emulate the effects of deep learning?** \n",
    ">>* In practice, successive applications of shallow-learning methods produce fast-diminishing returns, because the optimal first representation layer in a three-layer model isn’t the optimal first layer in a one-layer or two-layer model. What is transformative about deep learning is that it allows a model to learn all layers of representation jointly, at the same time, rather than in succession (greedily, as it’s called). With joint feature learning, whenever the model adjusts one of its internal features, all other features that depend on it automatically adapt to the change, without requiring human intervention. Everything is supervised by a single feedback signal: every change in the model serves the end goal. This is much more powerful than greedily stacking shallow models, because it allows for complex, abstract representations to be learned by breaking them down into long series of intermediate spaces (layers); each space is only a simple transformation away from the previous one.\n",
    ">>* These are the two essential characteristics of how deep learning learns from data: the incremental, layer-by-layer way in which increasingly complex representations are developed, and the fact that these intermediate incremental representations are learned jointly, each layer being updated to follow both the representational needs of the layer above and the needs of the layer below. Together, these two properties have made deep learning vastly more successful than previous approaches to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109b374",
   "metadata": {},
   "source": [
    ">* It turns out that top teams in kaggle competetions tend to use either `deep learning methods` (most often via the Keras library) or `gradient boosted trees` (most often via the LightGBM or XGBoost libraries).\n",
    ">> Specifically, `gradient boosted trees` is used for problems **where structured data** is available, whereas `deep learning` is used **for perceptual problems** such as image classification.\n",
    ">* This means you’ll need to be familiar with `Scikit-learn`, `XGBoost`, and `Keras`—the three libraries that currently dominate Kaggle competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7defb9",
   "metadata": {},
   "source": [
    ">* Regarding the computational power, there are two notes:\n",
    ">>* Nividia has invented RTX GPU which is able to do **16 trillion FLOPS** \"float operations per second\".\n",
    ">>* **`Cuda`** is the Nividia programming interface used for deep learning computations on NIVIDIA GPUs.\n",
    ">>* Also Google has invented a counterpart of the GPU called **TPU \"tensor processing unit\"** which is capable of running **100 petaFLOPS**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9fe9a3",
   "metadata": {},
   "source": [
    "Deep learning is good for the following reaosns:\n",
    ">* `Simplicity`—Deep learning removes the need for feature engineering, replacing complex, brittle, engineering-heavy pipelines with simple, end-to-end trainable models that are typically built using only five or six different tensor operations.\n",
    "\n",
    ">* `Scalability`—Deep learning is highly amenable to parallelization on GPUs or TPUs, so it can take full advantage of Moore’s law. In addition, deep learning models are trained by iterating over small batches of data, allowing them to be trained on datasets of arbitrary size. (The only bottleneck is the amount of parallel computational power available, which, thanks to Moore’s law, is a fast-moving barrier.)\n",
    "\n",
    ">* `Versatility and reusability (transfer learning)`—Unlike many prior machine learning approaches, deep learning models can be trained on additional data without restarting from scratch, making them viable for continuous online learning—an important property for very large production models. Furthermore, trained deep learning models are repurposable and thus reusable: for instance, **it’s possible to take a deep learning model trained for image classification and drop it into a video-processing pipeline**. This allows us to reinvest previous work into increasingly complex and powerful models. This also makes deep learning applicable to fairly small datasets.\n",
    "__________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
